node {
  name: "global_step/initial_value"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_step"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "global_step/Assign"
  op: "Assign"
  input: "global_step"
  input: "global_step/initial_value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "global_step/read"
  op: "Identity"
  input: "global_step"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "input"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
}
node {
  name: "output"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
}
node {
  name: "HistogramSummary/tag"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "X"
      }
    }
  }
}
node {
  name: "HistogramSummary"
  op: "HistogramSummary"
  input: "HistogramSummary/tag"
  input: "input"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "HistogramSummary_1/tag"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "y"
      }
    }
  }
}
node {
  name: "HistogramSummary_1"
  op: "HistogramSummary"
  input: "HistogramSummary_1/tag"
  input: "output"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected/weights/Initializer/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 8
          }
          dim {
            size: 190
          }
        }
        tensor_content: "\202z\261=\342\271l<\347\354\t>G\307\353\275\007\200/\276F\224\273\2740\237\270\274H\237\002=\003?\024\276\375\367\320<{\002\n>\276:\324=t~)\276Z\"\002\276V\314_\275\000Vf\275M\213\251=]\225\024=*Z!\276\232\2760>\216gL\275&\343\362\275\255\214\">\251\037{\275\301\030\004\275\2637\024\276\375\270\207\273\2647\037\276\302\376\001>\225\246\303=Xa\017\274\206{&\275\t\371\234=\035\375{\271bM\022\276\256\205\001\276w\250\334\275\264\007\275\275#\363\366=\232+\247\275\231)\'>\254g\320=\027\347\361=\346\241\355\275\256\201\365<0}c\275q\335U<\207\200\337\275\023\332^\275\275\337\261=?Y\212=\013\266\276=\333f\277=\005\307\225\275\357\001\024\276\344$s\2756K\334\275\333\r\254=\244:\027>\334\251\344<\357\273\324\275=j\246=\205lb=\226a\010>\215k$>\273X\027>\247E)>\357\220\021>\241q\337=R\362\364<\300=\340\2743\223\243\275\263\323\252\275>\307\266=W+l\274\227<\016\276R{\022\276\275g\324\275\357y\262\275\001\2617\275\307\302\034\274EK\207\274?\255\215=\005x\020>\312\311\230=\036\340\036\276\316\003\252=\372\364\210=PY\030\275\302\345\022>\343\250\010\274\027\303\'\276\347\337\303\275\351\020,>zg\307=l\254\240\275\3339\033>o\007>\274z\261\014>92\'\275\370\034\234=#\030\223<\004J\300\274\031\001\036>N\r\315\275\343\277\321=V\222\031>\334\016\207<9)\023\276\265\335<=\217k\001\276#i\004\276\243\325\">(\221\240\274:{\222\274\275\177\224=\247\212\363= \340\014\276\023\276c\275\037\023\312\274\225\371\035\276\025c \275|`k=y\2170\276\352?+>\3511\013>\014a\013\276\236\346\242\275\336\203\024\275\013w\377\275#\032\240\275\355\312\330\275\220\233w=E\276b\275Yp\363\275\215P\255\274\340X\233=\2444,=\322}\300\275@4\007>\272\204\236=T\036^\275\241b\'\2765\223\006>\255\347\r\276\3140\202\275\233s\376\273\316\274$\276\3558\033\276\314\227\302\275\322\001\262\273\341{\027>O\234s\275g\244\004>:\375j=\023\303P=\222\271\247=\366\251\027\276\222+ \276\216\206\267<\265\306/>\216\320\231\272\312\037\032>t|\"\276\255\265\354\275\326\237\037>\036\007\234=\"\261)\275\376\370\233\275\357\014\331\275Q\315\210=N\004\275\273\321T\231\274\037an\2752\356\006=c\376\020>\307\300\334=\'\354\033=\026\3441>\327\202\277=|\372\313\275\276\367\335\275XX%\275\260\310\000\276\303]\004\276\002p\027\276(\332\332\273\2729\224<\252\255%>\317\366\010\276L\237\331=\264\007\003\276\361\227\322\275{=\322=,\374h\275.y\026=\020\024\030\274\037\322\345\275\352(*>\177A\035\276\3247\351\275zD\000\276\345\372\254=\017\314\324;2\307\213=\315\244\352\274\314n.>\021\313\005>\355\303!=\260\351\223=\2772\371\273c\235\305=\275\242,\276\031\255@=q\033\353=\352\2614\2755G9\275\257\026%=J\nn=\344\327\003\275\234{\031\276B\252\034>\246;\260\275\313}\217=\00367\274cj+>T2\250<\205\321\000>FJ\303\275\262\0350<q1(>K\277\305<|\241\021\275?\303\267=\377#\217\275%R\036>9Q\222=xD\203\273\030\037\367\275[8\032\276\304\271\031>}~*\276u\033\321\275\353e\372\275g2\255=2\364\001\2760\032#\276\203\244R\275t#!\276\352\344\332=\320\027\"\275]p\224=\272U\364\2754\177#=\027\014\352\273\367\014.\275p2\250\274\321\337\022>B\237\316\275\256\005+>\347\326\333\275a\025\034>a\255 \274@\260\026\276}\245\010>5H\242\275\322P\267\275\357\004p=)>\262=\227\370\032<=%\277;\n\270y=a0!>\337f\376=\034P\356\274\276\245\322=\236\200\321\275\017\203#\276\277\237\255\274Rd\016\276\"\262\t\276\314\3265=+n%\2759\264\205=,\344|\275c\341\r\276{\273\254=\311\252\376\275D<\355\275\327\250\314=\240d\262=/\333\016>\303\261P\273q\222)>\247G\304=\317\003\200<\257\251 =\017\230\304\267\020>e=\301\221\033\276@\217\n\276\312c\006\276]Kj\275\003j\351\275\000o#\276%7\010=r^\334\275!^w=RI\206\2757\022\024\276mU\003\276\370\216\014=\0007\341=\200\256\312\275d\247!=\226\345$\276\340\224\020>I\262~\275\007P\t>Pc\243\274\253+\024\276j\"\205<zW\310\275\033,\314<\200\223\006\275\256\326#=\020\033)\276\253\346u\275\310\275\254:\367o\231\275\236}\'<\2300\\\274\327\377\355=\252M\267=-7\010>A\355 \276\224\203\035>n\347s=\2438\367=\253\306\t\274y\036\250=\234\315D=\346%\256\274\257\210\351=\243^-\275\t\326\373\275;\275\010\276\277\212\010\276[\361\370=\344]\305=}\241\255\272P\224\333=z6\035=\r5:=\263f\222=d\327\340=\377\247)\276\374\001\256=\013\231\317\275\240N\256<\233\321\001\274\013[E=\037\320\227=[Y\023>\022U/<K\217)\276\254d\013\276%\354\014>\202T\202\274dQ(\273\321<\342=\250\003}\274\253Y/\275,\316\010>\217\341\354\271*\256\361=\004\215.>\207j-\276\203\221\244<\363\364J\274\013\364@<.48=\'\330\352=\367q\036>\307\225\230=\257\014\027\276\035\225\275\275\022\250\030>\302%v\274WS\n>\366\022\230=\205E\221\275\350\026\214=\230\217\n\276\033\n\007>b\267\222=\322\225%>E3g= h\020>L\261\263=\351\321\325\275Z\365%>\236\350><\030\244\303\275/\240\335\275/\033\006>K!\321\275m\'\023\2760\260\016>Fr\001\2742\270\"\276\350v\213<\246\363x=?g*=\373\254*>*\263\323=\337\231\032\273\335\264\233\275\260g\344\275h\344 >\020\211\320=\037\227\312=z\210\246\275\222E\t\276c\231\217\275d\203\242\275\004\350\324=:\006\006>\266\3638\275\007\212\225\275\013\\\372=\203\207\257\275s\306\021>\333\306\361==\177\024\276\245\271\267\273\226`\226\274\013D$>\321\213\027>~\214\023>\362\227\000=\241\376\035>n\233\016>\000\254t\274\034\230\010\276\203\010\255=\271\205+\276\201\360\266=.\341\313\274\361\216\331=\245x\333\275\371\307\375\275s\357r\272\230\242#=\264~\037>\017\304\244\275\020\254\323=w\3444\275\2037\226\275\304\316\006\276\204T\316\275\311\321)\275\343\010\310\275\344\306}=\016H\362\273\361PN\275M\216\362\272\210z\210=\273\027\337\275\3062\273<\212\343y=,\324\247=\300;\372\272\356@\234\275\301\004\026\2769\240\033>\322M\234=\035O\265<\002o\267=q\023\013>\226\360\005\276\016\316^\275\342\2401>\306\010\n\276\350\036\262\275\361\345\364=\231\016\274\273\004\005\311\275\373\271\001=a\316\203\275%,\365=\025\270\306<\320\360\305=\255\312\225=\0130S=\366\321u=kG\005\276\250\177\002<\223kX=K\337.>C,+>\367\354\030\276\024m\271=\371p;=w\320\276=[\255\\\274\241l0=\215\001\301\274g7,\276\033#(\275\371\230\267\275|\371\267<\3059\230\275\263\r\323\274\034\227\033>6)\342=Q9\263\275\315s\305=\367\346\324=3j\361\275R\376\216\274\353\"\341=\2355\356\2740\202\232=TL\033>\035(\t\276\316\222\251=9\326\322\275\243tz\275EA\006\276B\200\034>\201T\n\276\230\032\201=\351\323\370=|\342\377\2752v\230\275\334\245 \276\347\020\r> \017\344\275\205\316\276=\3569\373=\222\010\342=\201^\327\275%]\025>\363\315:\275{\263\300<\251\366\316=\327\342\361=\375l!\2769\t\007=Q\366\"\276\361X\025>\322Z\034\276:<1>\227\305 \276$\375\341<\014m0\276\227\315\311=\032<\327<\334L_<8/\007\276g<\035>\314\274\364\275a\275\366=\201\315\036=#\226\'\276\314\230\037>\023l+\276l\247%>\300\327\252\275\243\016$>\353mw=\203\261\027=\233\360\355=fO\277\275\003\344\274=\322}\231=\003Wr<\300\2516=\254a@<p\007+\276\210s\274\274~\320\021=\t|\210<\214\351\364=[I(>\366\377\347\2740~%\276\301\355\366=\033\374\001>\332\221\353\273o\215\314=\177\360\351=2\035J\275h\235\2539\026\035\310<eZ\t>\303\201\233=\032\013P\275z\220\344=-\204\023\275\230\362$\276\211\305+>M\314\004\274\227\222\334\275\024=0\276p?\250\2748o\305\275\237:->\243\212G=\234\t-\276\352\346\204\275\236\033\024\275\r\245\202=\327\356\227=7\245\341\275:\306\323=k\026!>g\r\310=\354\266\371\275\364\\\357\275\273\222\266\275-\300\233=\335\241\023=PY\027\276\014\341\227\275\256,\005\276\216\214+>W%\263\275\027A\014>\255\312\r>e\327\216=F\203\244\275v\346,\275\033*\373\275\215\201\200=\037k\007\275w-\271<\211T\">\004s\341\275P\333H\275\\1\007>_\223`=j\230\275\275,\032\002\276\362\367\261=T\357\204=\262\224\006=k\371p<\327\313\021\273\336+$<\000\023\341\275\364\272\303\273\262[\230\275\316\256\350\274\346\006\302\275\026\226$>\004?v\274{\213\243\275Z\t\224=\217n\005\275\241\202\035>\313\001\036\276[`8\275\274\222\352\275\335Y7\274g0\365=:\337\020>\004\315\223=*\271\365=5\324\360<\357\325\374=F\261\236=\327`\232\275#\013 >\317v\237:W\277O=\213\033\030\275\013\225\313\274\230Y\270=n\324\217\275\323%\345\274\233\330\n>8\224\326\2753\271\367=\203\206!\276@\273\327\274H\267\177\275m\370\023\276\336O^\275\006\223\261<?\010\366=\236>d\275\303\201\026\2763x\352<\273\332&\276/\243\346=\024\307\315=\332\365e=\232\247\261\274\"\232Z\275=\341\313;\243\240\032>\213\201\005=\300k)=~f*\2765d\356\274\303R\206<\t\256\207=\032\202\037>\221\200\312=\000\251\330=\304\306\313=W\236\035>`\260\030>\010\230\326=\367\305\001\276 {\262=a\342\355\274\374R\360\275\214\010\030\276\233\203\255=lN\374<\255\252!;\310\211\007\276\264\304\237\275\343F\023\276\313\021\036>\360\352\037\276\240\021V\275\236\210\022\276\237\361\255=M\235]=\306\265\236=\210\2513\274\013\344\034>$s,\275\354.\260=O\023\366\271\021\267\373=\347\311\r\276\207\343)>m\032\005\276\274|\355\274I\361#\276\3252\206\274`\007.\276\177\240*\276\302U\351\275\3320\014>\332\014x=\370\272\003\276\272\344!\276\317\331\266\273D&\260<a_\363\274\244\375\267\2752)K=\212F\244\275\323\r\237<H\033\321<i\032W<\336\213.\276/\324p=\243\351\216=\n<$>pG\033>\366\"\216\275o&\275\275\022?\273=\216\222\273\274\235{\004=\265\353\360=\334(\321\275\367\037\203=-p\n>\301\372%\276\334\330!>p\311\255=\307\304N=\271{\273=\256Q%\276x\374\021>\364\221\022\276\371k\346\275\205*\017\276\236a\216\275\334\361\t\273\272dk\275\377\362\220=\325\347\237\275\303\231\316=\210T\t>6qc=c\231\336=Z\330A=c7<\275\376\307\333;\262G\217\274\023i\313\274\212\346\305\275:V\246\273&AR=Y\332\353\275j\003\345\273Bt#>\330\261\376=Lg\004>\233\234\222\273=\235\027=\r5(\276\177\361,>\270y)>\325\310\002=U\364!>\370K\317;\246\273\020>|\371\351=\261\337\345\274\022z\347<\202\261\241\275\360=\036\276\345!\n\2762n\026>1\n\214<\2729%\276\217\000\252\2742Ts\275G\0172\276\360\263\216\275\201\354.\276\251\202[<)\272]\274\275e\013>\270\315\354\275C\217\"\276\363i$\276\211\205\235\275fUN=\034\240\344\273<\352E\274\305\354\">\266\3601>\366\277\267=Z\373\257\274T\236\266\275e\020|\275\213K\007\276\341B\032\276A\230\204\275\n\202\036\276^\366\373\275{\272?=\2727\003\276\225\214b\274\342Y\215;\245\272\273<\251\036\301=eq\r\276?\272\031\276\013E\033>5\331\310=\002\333R\275\223.v=\"\363\331=\221-\014\276\357\177\304=\225E\353\274F\241\254\275\250\263)\276\016\273\201<_\345\031>\272\350C\2741`\200\274\356)G\275\211F\265\275\203\322)\275\214\273\361=\306\267\177=\315\0141\276\006\316(\2766\352\017\276\274\355\260=\300c\002\276W\003\362\275\006\260>\275\252W\221=\327H\030>\257\007\225\274\266\264\037<l_\262\275\0240\370\275\247\3163=zO+\276XC*=\302\240\366:\022\345\305=\326lR=\237%\t\276\251,~\2752\342\304\274h!\336\275\226\2152=:i >(\204|\274\307\231\202\275\344\r\n\276\200\002(\274\260R\2079\233\371\013\276\312\241\340<\232\2461\275\274\257\355=\366\221Q\275\343\"U;\340h.\267,K`=rc\033>\251\327\243\275\243\027r\275\232\014\332\274\246\343\262\275\221i\335<oP\325=+28\275\307\346\022\274\331I/<\307\253\331\275?\302\014>\027\341\023\276%*d<\263\357(\276n9\035>k\305;\275\230l\335\274\201\344\260=\327\260S<\211\274C=\317\017>\275\331\315\030\276K\337\031\276-\234\326\274!\272\031\275Y8\336\275\375\377\361\274*\037b\275\345\263\010\276\211\327\201\275\342\322\231\275\211\2571>\232Q!>\271\310\323=0\010\374=\271,\006\276\206{\231=Ti#>\t\213\022\276\266\200\222=\313\243u=\302<\343\275P\026\355=/P\375\275\034\376\306=0\201\246==C\357=\311\371\337=@\355\336=I{\377\275\214r\220\275\2331S\275\270\020\356=\364\357B\275\303\376\035\276\007\345\024\276:\002\221\275x\257m;\230\264\216\275\3338+>\304\363\313=5\"\345=\247\333\252=\313\364\357=\206\350\016\276\227\307\270=0\332U=\0344\030\276\325\231\t=;\375\025\276U\355\273=\025=\265<_\207$=\334\032\027\276\300\302\332=YT\256\274\345/\212=\027\357%\275\3235\323\275\tx\260\2748\353\r\276\233O1>D\271O\275P\007\375\275e\331,\275\207\275L=H\377d=\021\316\374<\216\025\005>\264\342\202=\273^\273\274#)==\362-\373=\022L\256\275\366\372\370=\340z\274=x>\232\274d\206\227=\035j\223\275\352p\274<Ra\023\275\005\340J\275\316H\203\275j\362&\276FB\360\275\223;\001>\331[0>\341w\007;\230\266I\275\311\316\254=\311\nB\274\254-\021>\202\374\017\276\307\3402\274b7\035>\276L\365\273\233\222?<\013\022\001>)x\201\275\302\311\201\275\037\310\341\275\317\211\327=$\017\266=6C\025\276`\217\246=\362\032i\275\344Gl<W\204.>\346g\014\275\214>\263\275\331\004\217<{\216$=.\347\332=\336\202\022\276\002f\n>\340\200\235=~\267!\276\340\t\312=\223\275\255=,\024\240\275\322/\231\275|\204\246=\210B0\274\225\223\251=\356\315\225\275=x]<\362\370\324\275\371\r\227=\256\232\310=\266\202\302=w\216\227\275\304\277\222\275N\244\033\276\025\014\351=\001\253\016\276\330H\r>\347\034.\275Y)\330=\027\303\376\275\004\240\200;\260\345\354=\210\330v=\361y\371=\340\200\350\275\273\014\353\275\274\222\000>\376\273\335\275P)\243\275\324\314,\276\267\013\017\2763\251&\276\346q;\275d\341l\275\321Bv=\030U\246=G\336\237=+\220\230\275\006\021\022\276j#\242=U\027\255\275YX\264=\343}\261\275Z\237\010\276\036\037\276=\352\336\005\276\216\221\255=Z\026\304=\2258\032>J\357\237=\366\013\202=avS\275H\317,>:\233\023\275.\271\014\276\336\004x<\005G\035<\200\243\237=\266{\t>9;\361=k\225\013\276\002\007\221=O\026 \276\362z\247\275D\373\014\276\313x\316\275\200\310\034\276bT\205\275\221+\225\273+]I=\220\026\030>\'\240\036\276\232Z\023=\255\315\361=\\\341\367\275Y\035\250=\262$\006>\370@\332=t\030\244\275&\243\263<6\245\215=\300\261\242=uT^=`\007\221\275v\237\277=\351\024\356\275\363\\\270\274O\333\260\274t\362\224=\343\004\320= \214\t\276\tZ\276<}\334\276\275\203\014&\276\ta\206=\224\257\000>)\2577\273\351@\252\275g?\346=\260xM\275\365\032\271=\265D\203\274_\351\r>NK\221=\334\357*>\220.\275\273\374\364\031\275\014\t~\2756\002\t>(\277\372\275H\330\240\275\013\216\242\275&\315R<l5\016\276\337>q\275\303\242\213\273\233\357\030\2767\336\000\276\024\313\003>R\346+>\303\017\220\275\331\357\017\276\375\343\357\275W\226\256\275Fc\275\275W\243t\275\210]q=d)i=\356\354\037>\177~&=D\266\244=h\031\036>W\227\255\275L\030_=\355\225\037>\373u.=\351\"z\275Tm\324<P\215\315;\366c\336\275\301T\302=_\263\202=\241\025\033\275\340\3558=\221\264#\276\245\263U\274!\026\271\274\024}k\275-\233\222=\031\032,\276%q\325\273\366\314\005\275\333\373\302=p\253\270\274\023\340\210\275C\364\344=\006\316B=_;\345=\203\246\364\274\025\265\272<P1\216<\3167*\275*\334\017>\025xv=\362?\025=\n\360\021\276r\324\364\274\333\003\r\276\215\314\321<{\031\231=u\2240\276F\253O=\034\370\376<\215D\302\275h\217\177;\377\033H\275\333\210%<{\367\006\276F9\235\275\340G\233\274\024\026!>~\261\036>\034V\225=\035W\364=\002\210\210=\234\260\204<\025c\016=\002\301\022<\225V4=\337\214\311=\331\265\312\274\210\321\343\275\274\204\030\275 %\035=\032\177)>*\362#>\353\235\246\275\233\241\262\274W\331\371\275\r\362\224\275g\222{\274L\244\231=c>\363\275H\220\014\276\344\013I\275)\r\200\275\347\365\"\276\232t\031\275*\375\006>\200\373\016>\377\254M=\341t!\276\245-.>k\314\024>\t\0162>\221\336\376=DB\004\276,\344\372\274Z\303\217=\004C\216=\210\010\204\275\251\031\350=\334\264\036\276(\257~=\354I\034\275I\"+=j\007p\275\341\220\005<{i\270\275\016\262\356\275K\277\252:\260\313\033>\224\350\000\276]s\300\275F\367\027=\3146\013>\341H\371\275\363\200\271\275`B\302=\362\257\036\276z`\304\275)\3341>\220\334\026\2762\254\010\276\256\014\270\273\232a1\276\276\034\320\275Z\023\026>\304\'h\274\253\315,\275df\246\275MQ\320<r\'2\2762{\225=9|,>\210:\177=\272\330\321\275r\2240>\232N\263=\013\366\024=\r\247/\276\233#\013\2769\212\032\276&}!\274\036\214\340\275\206Z1\276\000&0>\016\354S<}\367\251\275\254\024\237=\025\256\304\275-\327J\275\253\272\231=h\026\006\276\300rZ\275\214\3111>p\306\322\275\252\245\232\275u-\310\275\347\323\007\275\301n\017>\351P\310\275\252\205\016=K\276*>a\r\\<\204\335\234\275\215}\032>\306\027\036\276\356\231\377\275\257\tL\274!\215\350\275\317-\274\273\'^\357<\244\232A\274w\177(=\323}\214=H\321\201\275\252Z\320\275\367\037\333\275\323\357\310=\020\017\027>\025\264[\275\244\272\021>\337\305\304\275{\312\223<)\033\271\275\001\357\037\276\373GY=\032&\220\275\353\244\260\275\257\270\213\274\343\217p\275h\316\026;N,\003>\302\000\004\276\t\315\017\276\374\"\367\275V\300\007\274\352\345\311\274\302\335\301\275\276\024\204\275\310\023\237\2752\235\037;\021\307\357=\3046\247\275\314&\352\274\355\025\036\276\177\213\303=b\311\370\273T\360%=\247\247d\274]\265\001>q\314\021\276!(\t\276\004\245$>~7\275\275\277\007\342\275\351\364\204=\256\321\342\275n&\361=E\231&\276\321\235\236\275\272\177\002>\370\335\300\275\t*\260=\023\340\203\274\373>\256=\266b\344<&\302^<\341\353\231=\313\366\347=\270!\324\275\352\346\201\275RU:\275H\037\257\273\374\245\340<\370\007\005>\360\366\311=\036.?\275\236\022\014\275\343\233\031\276\272\255\232=kB\231\275\002\263\033\276\222r2\275^\250\205<t\254\371=\271\3222\275\2225\003>Xy\022=KG\000>]2\303=\030\300\t>E\242\330=B\351\004>\"H\300\275\267\002\023\2766\345\250\274\014V\342\275^l\216=\267\273 \273\211\3043\275p\311\353;\034h\231=\300\304\037\276\014\342\020=Ku\224=\213T\244=@/\365\275\303\332]\273\031\362k\275\027\374\312=*Y\334\275U\204\320\274\356z\023\275\364\333\r\276e\333\004>\302!\236=\257\215\025\276w\014\014\276\210\217!>\243\327+>\001\247\213=\267\004\250\273\200g\356\275o\225\017\275\254k1\276\225\206\237=\231\236Q=\246)\023\276A\270\317:\213\355\202\274\211\341\273=\274\204\200\275\\\327\302=2\211\212=\301\201\020\275&\034\371\275\227t\212\274P\355 >\\4\263<g\006g<\014\005\310=1/ >U\030\035>G\2524\273C\010\336\275\313\323\213\275\257\342\024=\035\267\357\274\334r\252\2758\322\277=V\351!=\007\227\363=\0302\310\273\274m\'>\257\366\336=\253\231\017\276\246\3521\276\372\002\275\273p\2400\276\372\323%\276X\327\261=\375\312\365\275\347\307\271=\014N\237<\273\216\033\275X\255\207\275K\370-\274\253\216\323=.\210\274\275nx%>\311\276\211=k\351\317=\273\324C\275\r\275\321<\213\014\247\275\374\246\233\275e\025\231=Q\312\021\276-\2211=l\213\367=\277\346\374="
      }
    }
  }
}
node {
  name: "fully_connected/weights"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 190
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected/weights/Assign"
  op: "Assign"
  input: "fully_connected/weights"
  input: "fully_connected/weights/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected/weights/read"
  op: "Identity"
  input: "fully_connected/weights"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected/MatMul"
  op: "MatMul"
  input: "input"
  input: "fully_connected/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "fully_connected/bias/Initializer/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 190
          }
        }
        tensor_content: "\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "fully_connected/bias"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 190
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected/bias/Assign"
  op: "Assign"
  input: "fully_connected/bias"
  input: "fully_connected/bias/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected/bias/read"
  op: "Identity"
  input: "fully_connected/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected/BiasAdd"
  op: "BiasAdd"
  input: "fully_connected/MatMul"
  input: "fully_connected/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected/Relu"
  op: "Relu"
  input: "fully_connected/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected_1/weights/Initializer/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 190
          }
          dim {
            size: 4
          }
        }
        tensor_content: "zt\364\274t\0164\276\036\352\320=\367\204\017>\005\272\342\275\021\253\213=Ch\025\276\017\377W\275\2321\037\276\332>\331=\363Y$>\256\306\267=\263\362\363=e\223\336=%)\365\275&\322\035=c\037\224=\277\264\220\275i\246\207\275>Y\252=\216f\314=\t\341-\276\357\r\361<\321\035;=\236\317\n>\200i\235\275\211\265m=VE\265=N $>\375\277\005>\225\2630>3\211c=\320\036\007\272p\247\n\276X\020\t\276\250t\032>\216y%\276F\347\251\275\370}&>\373U\300=-\0342\276WHW\275S\272%>\250\332\022>@2\035\276vd\007>\026\222\326\275b\001\220\275\031nu=\313L\235\275\227o`\275G\277\305\275\270\222\031\276\'\270w=\031\245\203\275o\275\264=\241\220\005\276\022]\320\275\242\263\217\274F\310*\276\326\266\000>t\002\022\276\232U\034\276b\276\331=\224\036J=8\013\003\276\212)\340<\313K\377\274%\372\216\275\025 \245<Y\037\250;\357\320l\275J\0244>m]\260\272.\2513>2\334 \276&=\270=o|\262\274p\330\006>|\354\351<\213g\214\275Mi.>\033\307\003>\320%\322\275\316\001\334<\031`\027\276-Su\274|(5=\312?$\2766\225{\275U\326\250\275U )>\313\272\362=\017\324\r\276@\026\375\275\037\243\025>N\235\223\273\326` >\002\016\030\276\005\212\247<O\220\332<pp\354\275w\t\276\275v\334&\276\242\005t\275\"\276\026=\302\241\323\274S\274\324=\344X\217=Mc\301\275L\303$\276|y5=\006\243\003>Z\271\201=\017\227+\276M\226\037\275\035\226J\275s\340\030\276\357\252\260\273a\030\345=\010\270P\273XMo=\242h\231=)\333M=\007\207_=\354\333\003\276\242X\025>\306\371\335\273\377\237\257\275\336f\024>\315\177\377\275\327e\277=\330\342\204=l\332\265=\272\352\024\276\244\3020\276\331\204\247\275r+\240=\034\217/:\353($\276H\260->\016\366D\274v\315\034\275d\265D<\241Q\356\275\033\360.>\036\265 \275rd\235\275\234\022\251=\022\324\206=\275\332\227\275\356\241\355=cc/\276m{\271<\030\020\371\274\313\261\304=\n\004\217\275\376\226\310=\356\016p\275A\031^<\327\372\310\275\007\2120>D\355,=\346?\'=\022\325\232\274\373S\001>~\242\275=\315\225&\276\033\224\230\275\016-B=4\307\315=\350E\226\275=\243\304=\344\315;<nDs=\360\017\331\275\274\325\363<\233\303\t\276\313b~=\234\266\014>i\260q\2756\311\205=8Q=\274\r\261\324\275Jy\336\274=H\212=\234E,=\247\360\202=\341\272/>\240\262\343\275\362\333\031>\330b\003>\234\356\026>\232\0252\275w\263\r\275E\343\361\275\247\254\300=`\222\"\275A\027\311\275a\377\247\275Q\206\261=\030I\032\276\005m\260=\231\036\035\276\320\n$\275\351\024\036=\2575\026\276\2244\244\274<\262/\276e\336\362<\023\235\033>\215\247\001\276\316e\271=s\276\214\275\345\010\032>:\036\'>\312\314\332:\203\313\r\276\252t\320\274j\024D=\237D\212\275\240\217\274\275\037\331V\275\007\001\317\272\222\021\031\276\005!\273=\354\202\000<\245(\000=\341\201\030>\030v8=\327e\240\275\244\250\362:\307\014(\276\204\336\026>\364E\030\276\"\224\375\275~\2121\276<\331\264=\304\337\362\275A\267M\275Z\204\017\276\'#\332\275\024\210\007>\0000+>\230w\362\275\377\r/\276\226\231\023\276\202\263\357\2750\330\240=C\033\330=\231\205\035>2\005\010>\234* \276\325m\243\2737\021\025>\231\367\331\275P\373O=}\342C=r\305!>\034R\372=\224}\025>Kx\010\276l\254\206\275\357?\266=\223\343s=\260l\000>Q\t\344\275\370I\201=}Y\357=&V.\275\t\266\010>4\013\370\275\'\345\251=\206\350\020\274;\304\255\274\321kv\275\354\263&\276\035\261\030>\020\270\263\274\365A\301=\336\310 \276\'\363\247=\004\360\366=\276{m\275\270o\337=zj#\276D\332/\274\tJ\350=\324L\215\2737\236\325=\224\232;\275\277\227\013=\370\307\010=lx\321<\225\322\307\275\353\331\034>\3050*\276]\244\231\274\232s\320=&Rz=\305\0202>a\224 >70\227=1\033\323\275Z\321->Y\367\010\276\272\212\004>_P\037\276\326I\010\276\215~?\275\322\034->\325Z\013>m\357\014\276\325 \270=\267T\022>\301Q\356\275\217\021\364\275#\212\000>\316\222\372<\313\346\026<\323U\257==\212\343<\212o\264=)`\r\276\201\264x=\327\272V\275\350\307\302\275\350\330)\275\256\177\010>\311\304*>\306\'\016=\302\342\357\275z$\027>H\033\006>|/\330=E\247\177;\327\026W=R%\212\275\313,\033\275\004\362-\276\022\324\213\275\nZ\235<\324H\257\274\261>\223\275\307\232\007\276l\215\r=w\274:\275\306\210\360\275\211\272\037>\236\035\206<\205Z\202\274hx->\252YW\275-\004\000>\252\370\'\275\340{\327=\nU\017\276\352\252\002\276\2670\307=\253]>:j\231\361=\205\317\372=`5\265=H0\025>\002G&>`\331,\276 \246A\274\001r\005\276\352\014+=\277\327\t\276\327\222%\276*n$=\203!\237\275\030\337U\275\360t\212\275:\223\245;i\224\246<#\324\210=b\367\352=\241\243\202=\000r\322\275\334\177\003\276=\372\007\276D\017\001\2758p#=W\312/\276\352\313\020>G\004\247\275\332\273\310\275\367\305\371\275=\027\317=2\340\362\275J\375\210\275\353t-\275C\363\220\275\211\033Y\275\010r\230\275\342\227\024\276d\226\300;\340\211\203=\214\357\017>\335F\030;g\312\n\275\275\274\342=\375\250\'\276\330\330\377<~\205A<y\366\214\275v\242\234<j\357}\275\372\277\314=\231\233\324=\035\326\356=\000P\t\276\3222\020>\337\323\003>y\210\324=[\220\322\275\222\004\006>\2018\026>W\250\346=\203)\221<\377\007\264\273\302\270\013>\276m\364=oi\031\276\252\301y\275\302\214\351\275\257\025\010>.P\016\276\353\032\340\274g\177\033>\355|\212\275`C\n\276\"~\355\275\207\302O\274\365=\363\275_\340!>\341\257\306\274G\212\010>\217\267\313<\314W\000\276\2617\006\2756l\363=T#\000\276\0072A=\230\000\013\276\312/\225\275b\302\232=t>7\275\236z\033=\374\335\374=\342\204\344=I\022\221\274\033\224g\275\315\200\025\2767FU\275\262\010\275\274\255c\020\276z\376\371\274wR\'=\014\024\251=\\k\334<;\3518\275\213\001\303\275\241\225\014\276P|\307=\341\210\260=v\036\324\275\335\373r=\363\336\255=\256\366\260;\306\262\277\275\276\323\236=C\010\370\273.\210\334<\221\245+=\346\243\241=\353\022^=\031j\315=8\016\032>\261\225\223\275[\251\007>ne%\276\352\2611\276\035\036\013>\216\320C\275|\351\206\275}A\326=\204\354\321\275\020\243\375\275\303\345\254=\266\340R\275\373\326+=h\214\306\274\230\363G\275\036\312\013>\007\261U<{|\374\275Y\211I=\210+*\276\217/\300=$OA\275\323\037\314<}\020\335\275\274O\306=^\352\243\275|$\332\273\265\257\322\275\233\022\224\272\271y\323\274U\256P=n\027\214=\362\317\236\275\222PL\275\334\266\303=\241\013\240=\023\204\320=\3471\321=\271!\265\275\r\263\257=\276\327\301=\370\017\005\276A\025\023=\271\353\331\274\273\017\002\276\320[\275\275\365<\004\276\252\312\220=x5\244<\306c8<\005\001\357;\341\267\003>Q*\'\276\206\215\354\275\353n\t>\274\217\001>\027\032!\275\177k\031\276`\373 \276}@\030>h\004n<\301\207\352=\'e\003\275\351=\013\276\312V2\2769\330\376\275\tpU=s\001/>\350\304&>\334\240\203=L(\035\276\345b\314=\261\235\315=\232\265\307=\210w\213<\227\3013>\365\341s\275\331\207\240\275\203\233\300<$$\033\276x\232I\274d\242\327\2758v\366\275\214\037\322\275 \t\325\275?\2543\2759\222->u\236\255=\241\202\r>C\347t=\216T\377=\200\330\311:{\003\020>6`\317<&\224~<\335\353\031\276\317v\n\2768\353\216\275e\211\013\276m\342\030\276\020C\004\275d\267\336\275rC >\325\026\024>h*=\275\264\261\022>.\376\202\275\275\310\263\275\364$~=~[\313=4\273U<{b\316=\365\315\270\274\224\206\341=\230\202\247\275\334\251\356\274/s;<VEL\275\243\022)\276vim\275\340\223\320=\344\t\254=\244\323\254\275_g&>\342V!\276\262-%>Y\2473\276|\241\244\275\2300\r>-i\210\275\241\216/=\364a%=\212c\304<\374(\245=Uu\001>\004\373\300\275\352\210D\275\336\034o<\017T\025\275C\214}\275x\351i\275T\341^=D\262 >\024\256j\275Q(\323<M\211\332\275\373\344\357:z]\320\273`u\312\274`\325:<L_\320:-@\213\275\345\222\346=\024\370\000\276\317<\003\276\177\354\370\275\021\243\020\276\320\034\037>\021\203\255\275\204f\207<\331f\266=\010u\331\274{p\024\276\211\364\310=@\177\200\275{ \362<2\n\205<\310\236\326=t|u\275\030\367\341=Yf\212\275a\2336\2754j\344<\234\022\007\275A*@=~)\300=,0\">e\346R<\217\356H<K\235T\275\375\204\201\275\332\200\350=\3702\306<\237\3167\275\277\004\314\275\237E\325=B\256\321=7\364\007=\262t\346=\030\367\237=8q\267\275\365\262\022\276\241 \273=U\241N=P\356\317=\345;\345\275\361:\212\274\237\250\000>\214\"\033=L\3121>\305\310\214\273)H\224=P\033\326=\346\241\352=\330C\225=\350%\r\276\261\2664=\026Z/\276x\353\034\276\257\244\003\276\233Cz=o?#>\252%\330\275\032\0041>V\327\016\276Qh\014>\310\024+>\236+\304<\255Z;=\267\303\205\275&1%\276\243\304\261<\247n\246\274\356\013\274=\346L\270=\376+9=\336,-\276\010n0\276t\366o=.:\003\276JC\213=e\377\"8\324\357&>\0266$>\213e\371\275\344\025J\272\365\343\\\275\377\352\354=\357\364\301=4\374\302=\023\214\037>\002\303\221=\344Z\365=&2\021>\033\004\370\275\034\331\232=,\030\276=\2409<<\017\247V\275D;\240<w\355\275=2\340\024\276\"@\362=\r\"\323\274\025\270\304\274\200\023\030\276><1\276.\337\216=X\251\315\275F_S\275\2037,\276MI\337=E\017\222\274\rh\031>4\310\032>\247\007\023<\361!#\276_:A\275\021{\255=\006\001\333\275\330\320-\276\227c\005>0r(\2764\265\001\276\264\014p;E\321\272;\300\002\026\276)\0064>\342\324,\276"
      }
    }
  }
}
node {
  name: "fully_connected_1/weights"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 190
        }
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected_1/weights/Assign"
  op: "Assign"
  input: "fully_connected_1/weights"
  input: "fully_connected_1/weights/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected_1/weights/read"
  op: "Identity"
  input: "fully_connected_1/weights"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected_1/MatMul"
  op: "MatMul"
  input: "fully_connected/Relu"
  input: "fully_connected_1/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "fully_connected_1/bias/Initializer/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "fully_connected_1/bias"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected_1/bias/Assign"
  op: "Assign"
  input: "fully_connected_1/bias"
  input: "fully_connected_1/bias/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected_1/bias/read"
  op: "Identity"
  input: "fully_connected_1/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected_1/BiasAdd"
  op: "BiasAdd"
  input: "fully_connected_1/MatMul"
  input: "fully_connected_1/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/HistogramSummary/tag"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression.X"
      }
    }
  }
}
node {
  name: "linear_regression/HistogramSummary"
  op: "HistogramSummary"
  input: "linear_regression/HistogramSummary/tag"
  input: "fully_connected_1/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/HistogramSummary_1/tag"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression.y"
      }
    }
  }
}
node {
  name: "linear_regression/HistogramSummary_1"
  op: "HistogramSummary"
  input: "linear_regression/HistogramSummary_1/tag"
  input: "output"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\004\000\000\000\004\000\000\000"
      }
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.866025388241
      }
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.866025388241
      }
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "linear_regression/weights/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 42
    }
  }
  attr {
    key: "seed2"
    value {
      i: 38
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform/sub"
  op: "Sub"
  input: "linear_regression/weights/Initializer/random_uniform/max"
  input: "linear_regression/weights/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform/mul"
  op: "Mul"
  input: "linear_regression/weights/Initializer/random_uniform/RandomUniform"
  input: "linear_regression/weights/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform"
  op: "Add"
  input: "linear_regression/weights/Initializer/random_uniform/mul"
  input: "linear_regression/weights/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/weights"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "linear_regression/weights/Assign"
  op: "Assign"
  input: "linear_regression/weights"
  input: "linear_regression/weights/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "linear_regression/weights/read"
  op: "Identity"
  input: "linear_regression/weights"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -1.73205077648
      }
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.73205077648
      }
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "linear_regression/bias/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 42
    }
  }
  attr {
    key: "seed2"
    value {
      i: 48
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform/sub"
  op: "Sub"
  input: "linear_regression/bias/Initializer/random_uniform/max"
  input: "linear_regression/bias/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform/mul"
  op: "Mul"
  input: "linear_regression/bias/Initializer/random_uniform/RandomUniform"
  input: "linear_regression/bias/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform"
  op: "Add"
  input: "linear_regression/bias/Initializer/random_uniform/mul"
  input: "linear_regression/bias/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/bias"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "linear_regression/bias/Assign"
  op: "Assign"
  input: "linear_regression/bias"
  input: "linear_regression/bias/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "linear_regression/bias/read"
  op: "Identity"
  input: "linear_regression/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/HistogramSummary_2/tag"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression.weights"
      }
    }
  }
}
node {
  name: "linear_regression/HistogramSummary_2"
  op: "HistogramSummary"
  input: "linear_regression/HistogramSummary_2/tag"
  input: "linear_regression/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/HistogramSummary_3/tag"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression.bias"
      }
    }
  }
}
node {
  name: "linear_regression/HistogramSummary_3"
  op: "HistogramSummary"
  input: "linear_regression/HistogramSummary_3/tag"
  input: "linear_regression/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul"
  op: "MatMul"
  input: "fully_connected_1/BiasAdd"
  input: "linear_regression/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/xw_plus_b"
  op: "BiasAdd"
  input: "linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul"
  input: "linear_regression/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/sub"
  op: "Sub"
  input: "output"
  input: "linear_regression/mean_squared_error_regressor/xw_plus_b"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/Mul"
  op: "Mul"
  input: "linear_regression/mean_squared_error_regressor/sub"
  input: "linear_regression/mean_squared_error_regressor/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/Rank"
  op: "Rank"
  input: "linear_regression/mean_squared_error_regressor/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/range/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/range/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/range"
  op: "Range"
  input: "linear_regression/mean_squared_error_regressor/range/start"
  input: "linear_regression/mean_squared_error_regressor/Rank"
  input: "linear_regression/mean_squared_error_regressor/range/delta"
}
node {
  name: "linear_regression/mean_squared_error_regressor/Mean"
  op: "Mean"
  input: "linear_regression/mean_squared_error_regressor/Mul"
  input: "linear_regression/mean_squared_error_regressor/range"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "ScalarSummary/tags"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "loss"
      }
    }
  }
}
node {
  name: "ScalarSummary"
  op: "ScalarSummary"
  input: "ScalarSummary/tags"
  input: "linear_regression/mean_squared_error_regressor/Mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "MergeSummary/MergeSummary"
  op: "MergeSummary"
  input: "HistogramSummary"
  input: "HistogramSummary_1"
  input: "linear_regression/HistogramSummary"
  input: "linear_regression/HistogramSummary_1"
  input: "linear_regression/HistogramSummary_2"
  input: "linear_regression/HistogramSummary_3"
  input: "ScalarSummary"
  attr {
    key: "N"
    value {
      i: 7
    }
  }
}
node {
  name: "learning_rate/Initializer/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.10000000149
      }
    }
  }
}
node {
  name: "learning_rate"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "learning_rate/Assign"
  op: "Assign"
  input: "learning_rate"
  input: "learning_rate/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "learning_rate/read"
  op: "Identity"
  input: "learning_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/Shape"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/Mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "gradients/Fill"
  op: "Fill"
  input: "gradients/Shape"
  input: "gradients/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Rank"
  op: "Rank"
  input: "linear_regression/mean_squared_error_regressor/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_1"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/range"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range"
  op: "Range"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range/start"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Rank"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range/delta"
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Fill/value"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Fill"
  op: "Fill"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_1"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range"
  input: "linear_regression/mean_squared_error_regressor/range"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/floordiv"
  op: "Div"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Reshape"
  op: "Reshape"
  input: "gradients/Fill"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Tile"
  op: "Tile"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Reshape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_2"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_3"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/Mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Rank_1"
  op: "Rank"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_2"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_1/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_1/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_1"
  op: "Range"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_1/start"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Rank_1"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_1/delta"
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Prod"
  op: "Prod"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_2"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Rank_2"
  op: "Rank"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_3"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_2/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_2/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_2"
  op: "Range"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_2/start"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Rank_2"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_2/delta"
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Prod_1"
  op: "Prod"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_3"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_2"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/floordiv_1"
  op: "Div"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Prod"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Prod_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Cast"
  op: "Cast"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/truediv"
  op: "Div"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Tile"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Shape"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Shape_1"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Shape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Shape_1"
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/mul"
  op: "Mul"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/truediv"
  input: "linear_regression/mean_squared_error_regressor/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Sum"
  op: "Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/mul"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/mul_1"
  op: "Mul"
  input: "linear_regression/mean_squared_error_regressor/sub"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/mul_1"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Sum_1"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN"
  op: "AddN"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Reshape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Reshape_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Shape"
  op: "Shape"
  input: "output"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Shape_1"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/xw_plus_b"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Shape"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Shape_1"
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Sum"
  op: "Sum"
  input: "gradients/AddN"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Reshape"
  op: "Reshape"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Neg"
  op: "Neg"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Neg"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/Rank"
  op: "Rank"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/sub/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/sub"
  op: "Sub"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/Rank"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/sub/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/range/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/range/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/range"
  op: "Range"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/range/start"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/sub"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/range/delta"
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/Sum"
  op: "Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Reshape_1"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/range"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Reshape_1"
  input: "linear_regression/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "fully_connected_1/BiasAdd"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/Rank"
  op: "Rank"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/sub/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/sub"
  op: "Sub"
  input: "gradients/fully_connected_1/BiasAdd_grad/Rank"
  input: "gradients/fully_connected_1/BiasAdd_grad/sub/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/range/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/range/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/range"
  op: "Range"
  input: "gradients/fully_connected_1/BiasAdd_grad/range/start"
  input: "gradients/fully_connected_1/BiasAdd_grad/sub"
  input: "gradients/fully_connected_1/BiasAdd_grad/range/delta"
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/Sum"
  op: "Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul"
  input: "gradients/fully_connected_1/BiasAdd_grad/range"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/fully_connected_1/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul"
  input: "fully_connected_1/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/fully_connected_1/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "fully_connected/Relu"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/fully_connected/Relu_grad/ReluGrad"
  op: "ReluGrad"
  input: "gradients/fully_connected_1/MatMul_grad/MatMul"
  input: "fully_connected/Relu"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/Rank"
  op: "Rank"
  input: "gradients/fully_connected/Relu_grad/ReluGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/sub/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/sub"
  op: "Sub"
  input: "gradients/fully_connected/BiasAdd_grad/Rank"
  input: "gradients/fully_connected/BiasAdd_grad/sub/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/range/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/range/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/range"
  op: "Range"
  input: "gradients/fully_connected/BiasAdd_grad/range/start"
  input: "gradients/fully_connected/BiasAdd_grad/sub"
  input: "gradients/fully_connected/BiasAdd_grad/range/delta"
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/Sum"
  op: "Sum"
  input: "gradients/fully_connected/Relu_grad/ReluGrad"
  input: "gradients/fully_connected/BiasAdd_grad/range"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/fully_connected/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/fully_connected/Relu_grad/ReluGrad"
  input: "fully_connected/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/fully_connected/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "input"
  input: "gradients/fully_connected/Relu_grad/ReluGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/mul"
  op: "Mul"
  input: "gradients/fully_connected/MatMul_grad/MatMul_1"
  input: "gradients/fully_connected/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank"
  op: "Rank"
  input: "global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range"
  op: "Range"
  input: "global_norm/range/start"
  input: "global_norm/Rank"
  input: "global_norm/range/delta"
}
node {
  name: "global_norm/Sum"
  op: "Sum"
  input: "global_norm/mul"
  input: "global_norm/range"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/mul_1"
  op: "Mul"
  input: "gradients/fully_connected/BiasAdd_grad/Sum"
  input: "gradients/fully_connected/BiasAdd_grad/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank_1"
  op: "Rank"
  input: "global_norm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range_1/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range_1/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range_1"
  op: "Range"
  input: "global_norm/range_1/start"
  input: "global_norm/Rank_1"
  input: "global_norm/range_1/delta"
}
node {
  name: "global_norm/Sum_1"
  op: "Sum"
  input: "global_norm/mul_1"
  input: "global_norm/range_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/mul_2"
  op: "Mul"
  input: "gradients/fully_connected_1/MatMul_grad/MatMul_1"
  input: "gradients/fully_connected_1/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank_2"
  op: "Rank"
  input: "global_norm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range_2/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range_2/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range_2"
  op: "Range"
  input: "global_norm/range_2/start"
  input: "global_norm/Rank_2"
  input: "global_norm/range_2/delta"
}
node {
  name: "global_norm/Sum_2"
  op: "Sum"
  input: "global_norm/mul_2"
  input: "global_norm/range_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/mul_3"
  op: "Mul"
  input: "gradients/fully_connected_1/BiasAdd_grad/Sum"
  input: "gradients/fully_connected_1/BiasAdd_grad/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank_3"
  op: "Rank"
  input: "global_norm/mul_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range_3/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range_3/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range_3"
  op: "Range"
  input: "global_norm/range_3/start"
  input: "global_norm/Rank_3"
  input: "global_norm/range_3/delta"
}
node {
  name: "global_norm/Sum_3"
  op: "Sum"
  input: "global_norm/mul_3"
  input: "global_norm/range_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/mul_4"
  op: "Mul"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul_1"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank_4"
  op: "Rank"
  input: "global_norm/mul_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range_4/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range_4/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range_4"
  op: "Range"
  input: "global_norm/range_4/start"
  input: "global_norm/Rank_4"
  input: "global_norm/range_4/delta"
}
node {
  name: "global_norm/Sum_4"
  op: "Sum"
  input: "global_norm/mul_4"
  input: "global_norm/range_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/mul_5"
  op: "Mul"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank_5"
  op: "Rank"
  input: "global_norm/mul_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range_5/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range_5/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range_5"
  op: "Range"
  input: "global_norm/range_5/start"
  input: "global_norm/Rank_5"
  input: "global_norm/range_5/delta"
}
node {
  name: "global_norm/Sum_5"
  op: "Sum"
  input: "global_norm/mul_5"
  input: "global_norm/range_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/pack"
  op: "Pack"
  input: "global_norm/Sum"
  input: "global_norm/Sum_1"
  input: "global_norm/Sum_2"
  input: "global_norm/Sum_3"
  input: "global_norm/Sum_4"
  input: "global_norm/Sum_5"
  attr {
    key: "N"
    value {
      i: 6
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank_6"
  op: "Rank"
  input: "global_norm/pack"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range_6/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range_6/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range_6"
  op: "Range"
  input: "global_norm/range_6/start"
  input: "global_norm/Rank_6"
  input: "global_norm/range_6/delta"
}
node {
  name: "global_norm/Sum_6"
  op: "Sum"
  input: "global_norm/pack"
  input: "global_norm/range_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/global_norm"
  op: "Sqrt"
  input: "global_norm/Sum_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/truediv/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "clip_by_global_norm/truediv"
  op: "Div"
  input: "clip_by_global_norm/truediv/x"
  input: "global_norm/global_norm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.20000000298
      }
    }
  }
}
node {
  name: "clip_by_global_norm/Minimum"
  op: "Minimum"
  input: "clip_by_global_norm/truediv"
  input: "clip_by_global_norm/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 5.0
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul"
  op: "Mul"
  input: "clip_by_global_norm/mul/x"
  input: "clip_by_global_norm/Minimum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul_1"
  op: "Mul"
  input: "gradients/fully_connected/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_0"
  op: "Identity"
  input: "clip_by_global_norm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul_2"
  op: "Mul"
  input: "gradients/fully_connected/BiasAdd_grad/Sum"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_1"
  op: "Identity"
  input: "clip_by_global_norm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul_3"
  op: "Mul"
  input: "gradients/fully_connected_1/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_2"
  op: "Identity"
  input: "clip_by_global_norm/mul_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul_4"
  op: "Mul"
  input: "gradients/fully_connected_1/BiasAdd_grad/Sum"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_3"
  op: "Identity"
  input: "clip_by_global_norm/mul_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul_5"
  op: "Mul"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_4"
  op: "Identity"
  input: "clip_by_global_norm/mul_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul_6"
  op: "Mul"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/Sum"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_5"
  op: "Identity"
  input: "clip_by_global_norm/mul_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "beta1_power/initial_value"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.899999976158
      }
    }
  }
}
node {
  name: "beta1_power"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "beta1_power/Assign"
  op: "Assign"
  input: "beta1_power"
  input: "beta1_power/initial_value"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "beta1_power/read"
  op: "Identity"
  input: "beta1_power"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "beta2_power/initial_value"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.999000012875
      }
    }
  }
}
node {
  name: "beta2_power"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "beta2_power/Assign"
  op: "Assign"
  input: "beta2_power"
  input: "beta2_power/initial_value"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "beta2_power/read"
  op: "Identity"
  input: "beta2_power"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 8
          }
          dim {
            size: 190
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected/weights/Adam"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 190
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected/weights/Adam/Assign"
  op: "Assign"
  input: "fully_connected/weights/Adam"
  input: "zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected/weights/Adam/read"
  op: "Identity"
  input: "fully_connected/weights/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 8
          }
          dim {
            size: 190
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected/weights/Adam_1"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 190
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected/weights/Adam_1/Assign"
  op: "Assign"
  input: "fully_connected/weights/Adam_1"
  input: "zeros_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected/weights/Adam_1/read"
  op: "Identity"
  input: "fully_connected/weights/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 190
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected/bias/Adam"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 190
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected/bias/Adam/Assign"
  op: "Assign"
  input: "fully_connected/bias/Adam"
  input: "zeros_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected/bias/Adam/read"
  op: "Identity"
  input: "fully_connected/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 190
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected/bias/Adam_1"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 190
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected/bias/Adam_1/Assign"
  op: "Assign"
  input: "fully_connected/bias/Adam_1"
  input: "zeros_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected/bias/Adam_1/read"
  op: "Identity"
  input: "fully_connected/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_4"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 190
          }
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected_1/weights/Adam"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 190
        }
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected_1/weights/Adam/Assign"
  op: "Assign"
  input: "fully_connected_1/weights/Adam"
  input: "zeros_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected_1/weights/Adam/read"
  op: "Identity"
  input: "fully_connected_1/weights/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_5"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 190
          }
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected_1/weights/Adam_1"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 190
        }
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected_1/weights/Adam_1/Assign"
  op: "Assign"
  input: "fully_connected_1/weights/Adam_1"
  input: "zeros_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected_1/weights/Adam_1/read"
  op: "Identity"
  input: "fully_connected_1/weights/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_6"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected_1/bias/Adam"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected_1/bias/Adam/Assign"
  op: "Assign"
  input: "fully_connected_1/bias/Adam"
  input: "zeros_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected_1/bias/Adam/read"
  op: "Identity"
  input: "fully_connected_1/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_7"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected_1/bias/Adam_1"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected_1/bias/Adam_1/Assign"
  op: "Assign"
  input: "fully_connected_1/bias/Adam_1"
  input: "zeros_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected_1/bias/Adam_1/read"
  op: "Identity"
  input: "fully_connected_1/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_8"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "linear_regression/weights/Adam"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "linear_regression/weights/Adam/Assign"
  op: "Assign"
  input: "linear_regression/weights/Adam"
  input: "zeros_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "linear_regression/weights/Adam/read"
  op: "Identity"
  input: "linear_regression/weights/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_9"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "linear_regression/weights/Adam_1"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "linear_regression/weights/Adam_1/Assign"
  op: "Assign"
  input: "linear_regression/weights/Adam_1"
  input: "zeros_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "linear_regression/weights/Adam_1/read"
  op: "Identity"
  input: "linear_regression/weights/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_10"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "linear_regression/bias/Adam"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "linear_regression/bias/Adam/Assign"
  op: "Assign"
  input: "linear_regression/bias/Adam"
  input: "zeros_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "linear_regression/bias/Adam/read"
  op: "Identity"
  input: "linear_regression/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_11"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "linear_regression/bias/Adam_1"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "linear_regression/bias/Adam_1/Assign"
  op: "Assign"
  input: "linear_regression/bias/Adam_1"
  input: "zeros_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "linear_regression/bias/Adam_1/read"
  op: "Identity"
  input: "linear_regression/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "train/beta1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.899999976158
      }
    }
  }
}
node {
  name: "train/beta2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.999000012875
      }
    }
  }
}
node {
  name: "train/epsilon"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 9.99999993923e-09
      }
    }
  }
}
node {
  name: "train/update_fully_connected/weights/ApplyAdam"
  op: "ApplyAdam"
  input: "fully_connected/weights"
  input: "fully_connected/weights/Adam"
  input: "fully_connected/weights/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "learning_rate/read"
  input: "train/beta1"
  input: "train/beta2"
  input: "train/epsilon"
  input: "clip_by_global_norm/clip_by_global_norm/_0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "train/update_fully_connected/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "fully_connected/bias"
  input: "fully_connected/bias/Adam"
  input: "fully_connected/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "learning_rate/read"
  input: "train/beta1"
  input: "train/beta2"
  input: "train/epsilon"
  input: "clip_by_global_norm/clip_by_global_norm/_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "train/update_fully_connected_1/weights/ApplyAdam"
  op: "ApplyAdam"
  input: "fully_connected_1/weights"
  input: "fully_connected_1/weights/Adam"
  input: "fully_connected_1/weights/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "learning_rate/read"
  input: "train/beta1"
  input: "train/beta2"
  input: "train/epsilon"
  input: "clip_by_global_norm/clip_by_global_norm/_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "train/update_fully_connected_1/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "fully_connected_1/bias"
  input: "fully_connected_1/bias/Adam"
  input: "fully_connected_1/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "learning_rate/read"
  input: "train/beta1"
  input: "train/beta2"
  input: "train/epsilon"
  input: "clip_by_global_norm/clip_by_global_norm/_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "train/update_linear_regression/weights/ApplyAdam"
  op: "ApplyAdam"
  input: "linear_regression/weights"
  input: "linear_regression/weights/Adam"
  input: "linear_regression/weights/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "learning_rate/read"
  input: "train/beta1"
  input: "train/beta2"
  input: "train/epsilon"
  input: "clip_by_global_norm/clip_by_global_norm/_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "train/update_linear_regression/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "linear_regression/bias"
  input: "linear_regression/bias/Adam"
  input: "linear_regression/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "learning_rate/read"
  input: "train/beta1"
  input: "train/beta2"
  input: "train/epsilon"
  input: "clip_by_global_norm/clip_by_global_norm/_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "train/mul"
  op: "Mul"
  input: "beta1_power/read"
  input: "train/beta1"
  input: "^train/update_fully_connected/weights/ApplyAdam"
  input: "^train/update_fully_connected/bias/ApplyAdam"
  input: "^train/update_fully_connected_1/weights/ApplyAdam"
  input: "^train/update_fully_connected_1/bias/ApplyAdam"
  input: "^train/update_linear_regression/weights/ApplyAdam"
  input: "^train/update_linear_regression/bias/ApplyAdam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "train/Assign"
  op: "Assign"
  input: "beta1_power"
  input: "train/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "train/mul_1"
  op: "Mul"
  input: "beta2_power/read"
  input: "train/beta2"
  input: "^train/update_fully_connected/weights/ApplyAdam"
  input: "^train/update_fully_connected/bias/ApplyAdam"
  input: "^train/update_fully_connected_1/weights/ApplyAdam"
  input: "^train/update_fully_connected_1/bias/ApplyAdam"
  input: "^train/update_linear_regression/weights/ApplyAdam"
  input: "^train/update_linear_regression/bias/ApplyAdam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "train/Assign_1"
  op: "Assign"
  input: "beta2_power"
  input: "train/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "train/update"
  op: "NoOp"
  input: "^train/update_fully_connected/weights/ApplyAdam"
  input: "^train/update_fully_connected/bias/ApplyAdam"
  input: "^train/update_fully_connected_1/weights/ApplyAdam"
  input: "^train/update_fully_connected_1/bias/ApplyAdam"
  input: "^train/update_linear_regression/weights/ApplyAdam"
  input: "^train/update_linear_regression/bias/ApplyAdam"
  input: "^train/Assign"
  input: "^train/Assign_1"
}
node {
  name: "train/value"
  op: "Const"
  input: "^train/update"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "train"
  op: "AssignAdd"
  input: "global_step"
  input: "train/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "group_deps"
  op: "NoOp"
  input: "^train"
}
node {
  name: "init"
  op: "NoOp"
  input: "^global_step/Assign"
  input: "^fully_connected/weights/Assign"
  input: "^fully_connected/bias/Assign"
  input: "^fully_connected_1/weights/Assign"
  input: "^fully_connected_1/bias/Assign"
  input: "^linear_regression/weights/Assign"
  input: "^linear_regression/bias/Assign"
  input: "^learning_rate/Assign"
  input: "^beta1_power/Assign"
  input: "^beta2_power/Assign"
  input: "^fully_connected/weights/Adam/Assign"
  input: "^fully_connected/weights/Adam_1/Assign"
  input: "^fully_connected/bias/Adam/Assign"
  input: "^fully_connected/bias/Adam_1/Assign"
  input: "^fully_connected_1/weights/Adam/Assign"
  input: "^fully_connected_1/weights/Adam_1/Assign"
  input: "^fully_connected_1/bias/Adam/Assign"
  input: "^fully_connected_1/bias/Adam_1/Assign"
  input: "^linear_regression/weights/Adam/Assign"
  input: "^linear_regression/weights/Adam_1/Assign"
  input: "^linear_regression/bias/Adam/Assign"
  input: "^linear_regression/bias/Adam_1/Assign"
}
node {
  name: "save/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "model"
      }
    }
  }
}
node {
  name: "save/save/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 22
          }
        }
        string_val: "beta1_power"
        string_val: "beta2_power"
        string_val: "fully_connected/bias"
        string_val: "fully_connected/bias/Adam"
        string_val: "fully_connected/bias/Adam_1"
        string_val: "fully_connected/weights"
        string_val: "fully_connected/weights/Adam"
        string_val: "fully_connected/weights/Adam_1"
        string_val: "fully_connected_1/bias"
        string_val: "fully_connected_1/bias/Adam"
        string_val: "fully_connected_1/bias/Adam_1"
        string_val: "fully_connected_1/weights"
        string_val: "fully_connected_1/weights/Adam"
        string_val: "fully_connected_1/weights/Adam_1"
        string_val: "global_step"
        string_val: "learning_rate"
        string_val: "linear_regression/bias"
        string_val: "linear_regression/bias/Adam"
        string_val: "linear_regression/bias/Adam_1"
        string_val: "linear_regression/weights"
        string_val: "linear_regression/weights/Adam"
        string_val: "linear_regression/weights/Adam_1"
      }
    }
  }
}
node {
  name: "save/save/shapes_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 22
          }
        }
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
      }
    }
  }
}
node {
  name: "save/save"
  op: "SaveSlices"
  input: "save/Const"
  input: "save/save/tensor_names"
  input: "save/save/shapes_and_slices"
  input: "beta1_power"
  input: "beta2_power"
  input: "fully_connected/bias"
  input: "fully_connected/bias/Adam"
  input: "fully_connected/bias/Adam_1"
  input: "fully_connected/weights"
  input: "fully_connected/weights/Adam"
  input: "fully_connected/weights/Adam_1"
  input: "fully_connected_1/bias"
  input: "fully_connected_1/bias/Adam"
  input: "fully_connected_1/bias/Adam_1"
  input: "fully_connected_1/weights"
  input: "fully_connected_1/weights/Adam"
  input: "fully_connected_1/weights/Adam_1"
  input: "global_step"
  input: "learning_rate"
  input: "linear_regression/bias"
  input: "linear_regression/bias/Adam"
  input: "linear_regression/bias/Adam_1"
  input: "linear_regression/weights"
  input: "linear_regression/weights/Adam"
  input: "linear_regression/weights/Adam_1"
  attr {
    key: "T"
    value {
      list {
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_INT32
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/control_dependency"
  op: "Identity"
  input: "save/Const"
  input: "^save/save"
  attr {
    key: "T"
    value {
      type: DT_STRING
    }
  }
}
node {
  name: "save/restore_slice/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "beta1_power"
      }
    }
  }
}
node {
  name: "save/restore_slice/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice/tensor_name"
  input: "save/restore_slice/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign"
  op: "Assign"
  input: "beta1_power"
  input: "save/restore_slice"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_1/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "beta2_power"
      }
    }
  }
}
node {
  name: "save/restore_slice_1/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_1"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_1/tensor_name"
  input: "save/restore_slice_1/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_1"
  op: "Assign"
  input: "beta2_power"
  input: "save/restore_slice_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_2/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected/bias"
      }
    }
  }
}
node {
  name: "save/restore_slice_2/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_2"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_2/tensor_name"
  input: "save/restore_slice_2/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_2"
  op: "Assign"
  input: "fully_connected/bias"
  input: "save/restore_slice_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_3/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected/bias/Adam"
      }
    }
  }
}
node {
  name: "save/restore_slice_3/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_3"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_3/tensor_name"
  input: "save/restore_slice_3/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_3"
  op: "Assign"
  input: "fully_connected/bias/Adam"
  input: "save/restore_slice_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_4/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected/bias/Adam_1"
      }
    }
  }
}
node {
  name: "save/restore_slice_4/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_4"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_4/tensor_name"
  input: "save/restore_slice_4/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_4"
  op: "Assign"
  input: "fully_connected/bias/Adam_1"
  input: "save/restore_slice_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_5/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected/weights"
      }
    }
  }
}
node {
  name: "save/restore_slice_5/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_5"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_5/tensor_name"
  input: "save/restore_slice_5/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_5"
  op: "Assign"
  input: "fully_connected/weights"
  input: "save/restore_slice_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_6/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected/weights/Adam"
      }
    }
  }
}
node {
  name: "save/restore_slice_6/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_6"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_6/tensor_name"
  input: "save/restore_slice_6/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_6"
  op: "Assign"
  input: "fully_connected/weights/Adam"
  input: "save/restore_slice_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_7/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected/weights/Adam_1"
      }
    }
  }
}
node {
  name: "save/restore_slice_7/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_7"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_7/tensor_name"
  input: "save/restore_slice_7/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_7"
  op: "Assign"
  input: "fully_connected/weights/Adam_1"
  input: "save/restore_slice_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_8/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected_1/bias"
      }
    }
  }
}
node {
  name: "save/restore_slice_8/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_8"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_8/tensor_name"
  input: "save/restore_slice_8/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_8"
  op: "Assign"
  input: "fully_connected_1/bias"
  input: "save/restore_slice_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_9/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected_1/bias/Adam"
      }
    }
  }
}
node {
  name: "save/restore_slice_9/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_9"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_9/tensor_name"
  input: "save/restore_slice_9/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_9"
  op: "Assign"
  input: "fully_connected_1/bias/Adam"
  input: "save/restore_slice_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_10/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected_1/bias/Adam_1"
      }
    }
  }
}
node {
  name: "save/restore_slice_10/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_10"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_10/tensor_name"
  input: "save/restore_slice_10/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_10"
  op: "Assign"
  input: "fully_connected_1/bias/Adam_1"
  input: "save/restore_slice_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_11/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected_1/weights"
      }
    }
  }
}
node {
  name: "save/restore_slice_11/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_11"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_11/tensor_name"
  input: "save/restore_slice_11/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_11"
  op: "Assign"
  input: "fully_connected_1/weights"
  input: "save/restore_slice_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_12/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected_1/weights/Adam"
      }
    }
  }
}
node {
  name: "save/restore_slice_12/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_12"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_12/tensor_name"
  input: "save/restore_slice_12/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_12"
  op: "Assign"
  input: "fully_connected_1/weights/Adam"
  input: "save/restore_slice_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_13/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected_1/weights/Adam_1"
      }
    }
  }
}
node {
  name: "save/restore_slice_13/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_13"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_13/tensor_name"
  input: "save/restore_slice_13/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_13"
  op: "Assign"
  input: "fully_connected_1/weights/Adam_1"
  input: "save/restore_slice_13"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_14/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "global_step"
      }
    }
  }
}
node {
  name: "save/restore_slice_14/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_14"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_14/tensor_name"
  input: "save/restore_slice_14/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_14"
  op: "Assign"
  input: "global_step"
  input: "save/restore_slice_14"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_15/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "learning_rate"
      }
    }
  }
}
node {
  name: "save/restore_slice_15/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_15"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_15/tensor_name"
  input: "save/restore_slice_15/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_15"
  op: "Assign"
  input: "learning_rate"
  input: "save/restore_slice_15"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_16/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression/bias"
      }
    }
  }
}
node {
  name: "save/restore_slice_16/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_16"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_16/tensor_name"
  input: "save/restore_slice_16/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_16"
  op: "Assign"
  input: "linear_regression/bias"
  input: "save/restore_slice_16"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_17/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression/bias/Adam"
      }
    }
  }
}
node {
  name: "save/restore_slice_17/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_17"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_17/tensor_name"
  input: "save/restore_slice_17/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_17"
  op: "Assign"
  input: "linear_regression/bias/Adam"
  input: "save/restore_slice_17"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_18/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression/bias/Adam_1"
      }
    }
  }
}
node {
  name: "save/restore_slice_18/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_18"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_18/tensor_name"
  input: "save/restore_slice_18/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_18"
  op: "Assign"
  input: "linear_regression/bias/Adam_1"
  input: "save/restore_slice_18"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_19/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression/weights"
      }
    }
  }
}
node {
  name: "save/restore_slice_19/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_19"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_19/tensor_name"
  input: "save/restore_slice_19/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_19"
  op: "Assign"
  input: "linear_regression/weights"
  input: "save/restore_slice_19"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_20/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression/weights/Adam"
      }
    }
  }
}
node {
  name: "save/restore_slice_20/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_20"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_20/tensor_name"
  input: "save/restore_slice_20/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_20"
  op: "Assign"
  input: "linear_regression/weights/Adam"
  input: "save/restore_slice_20"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_21/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression/weights/Adam_1"
      }
    }
  }
}
node {
  name: "save/restore_slice_21/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_21"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_21/tensor_name"
  input: "save/restore_slice_21/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_21"
  op: "Assign"
  input: "linear_regression/weights/Adam_1"
  input: "save/restore_slice_21"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_all"
  op: "NoOp"
  input: "^save/Assign"
  input: "^save/Assign_1"
  input: "^save/Assign_2"
  input: "^save/Assign_3"
  input: "^save/Assign_4"
  input: "^save/Assign_5"
  input: "^save/Assign_6"
  input: "^save/Assign_7"
  input: "^save/Assign_8"
  input: "^save/Assign_9"
  input: "^save/Assign_10"
  input: "^save/Assign_11"
  input: "^save/Assign_12"
  input: "^save/Assign_13"
  input: "^save/Assign_14"
  input: "^save/Assign_15"
  input: "^save/Assign_16"
  input: "^save/Assign_17"
  input: "^save/Assign_18"
  input: "^save/Assign_19"
  input: "^save/Assign_20"
  input: "^save/Assign_21"
}
versions {
  producer: 8
}
