{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __init__ import *\n",
    "from FeedFlow import FeedFlow\n",
    "from SlidingWindowUtil import SlidingWindow\n",
    "import matplotlib.pyplot as plt\n",
    "from NeuralFlow import NeuralFlowRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vm_name = \" 17d13bbf-a55d-4f8e-ad9e-c739e12db98d \"\n",
    "n_size = 5\n",
    "n_range = 28919\n",
    "total_cpu_util = pd.read_hdf(\"sample_cpu_util\")[\"Volume\"]\n",
    "total_disk_write = pd.read_hdf(\"sample_disk_write\")[\"Volume\"]\n",
    "\n",
    "scaler  = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "disk_write_scaler = scaler.fit_transform(total_disk_write[:n_range].reshape(-1,1))\n",
    "disk_write_X = list(SlidingWindow(disk_write_scaler,n_size))\n",
    "cpu_scaler = scaler.fit_transform(total_cpu_util[:n_range].reshape(-1,1))\n",
    "cpu_util_X =  list(SlidingWindow(cpu_scaler,n_size))\n",
    "\n",
    "disk_write_y = disk_write_scaler[n_size-1:]\n",
    "cpu_util_y = cpu_scaler[n_size-1:]\n",
    "\n",
    "X_train = np.asarray([np.array(t,dtype=np.float32).flatten().tolist() for t in zip(cpu_util_X,disk_write_X)])\n",
    "y_train = np.asarray([np.array(t).flatten().tolist() for t in zip(cpu_util_y,disk_write_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler  = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "disk_write_scaler = scaler.fit_transform(total_disk_write[n_range:].reshape(-1,1))\n",
    "disk_write_X = list(SlidingWindow(disk_write_scaler,n_size))\n",
    "cpu_scaler = scaler.fit_transform(total_cpu_util[n_range:].reshape(-1,1))\n",
    "cpu_util_X =  list(SlidingWindow(cpu_scaler,n_size))\n",
    "\n",
    "disk_write_y = disk_write_scaler[n_size-1:]\n",
    "cpu_util_y = cpu_scaler[n_size-1:]\n",
    "\n",
    "X_test = np.asarray([np.array(t,dtype=np.float32).flatten().tolist() for t in zip(cpu_util_X,disk_write_X)])\n",
    "y_test = np.asarray([np.array(t).flatten().tolist() for t in zip(cpu_util_y,disk_write_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization\n"
     ]
    }
   ],
   "source": [
    "fit_param = {\n",
    "    'neural_shape':[2*n_size,15,2]\n",
    "}\n",
    "neuralNet = NeuralFlowRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# kfold = KFold(X_train.shape[0],10)\n",
    "# score_lst = np.zeros(len(kfold),dtype=np.float32)\n",
    "# for k,(train,test) in enumerate(kfold):\n",
    "#     a = neuralNet.fit(X_train[train],y_train[train],**fit_param)\n",
    "#     score_lst[k]=neuralNet.score(X_train[test],y_train[test])\n",
    "# print score_lst.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #99, avg. train loss: 0.07466\n",
      "Step #199, avg. train loss: 0.00259\n",
      "Step #300, epoch #1, avg. train loss: 0.00103\n",
      "Step #400, epoch #1, avg. train loss: 0.00082\n",
      "Step #500, epoch #1, avg. train loss: 0.00062\n",
      "Step #600, epoch #2, avg. train loss: 0.00048\n",
      "Step #700, epoch #2, avg. train loss: 0.00047\n",
      "Step #800, epoch #2, avg. train loss: 0.00047\n",
      "Step #900, epoch #3, avg. train loss: 0.00044\n",
      "Step #1000, epoch #3, avg. train loss: 0.00041\n"
     ]
    }
   ],
   "source": [
    "# neuralNet.save(\"pa2\")\n",
    "a = neuralNet.fit(X_train,y_train,**fit_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = neuralNet.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_shape = \"%s-%s\"%(4,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result[nn_shape]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4-10': 2, '4-11': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(result,orient='index').to_json(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
